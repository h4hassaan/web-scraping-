import requests
from bs4 import BeautifulSoup
import pandas as pd

titles = []
companies = []
locations = []
dates = []


web = requests.get("https://realpython.github.io/fake-jobs/")
soup = BeautifulSoup(web.content , "html.parser")

for job in soup.find_all("div",class_="card-content"):
   
   title = job.find("h2", class_= "title is-5").get_text()
   titles.append(title)
   
   company = job.find("h3", class_="subtitle is-6 company").get_text()
   companies.append(company)
   
   location = job.find("p",class_="location").get_text()
   locations.append(location)
   
   date = job.find("time")["datetime"]
   dates.append(date)
   
data = pd.DataFrame({
   "titles" : titles ,
   "companies" : companies ,
   "locations" : locations ,
   "dates" : date
})

data.to_csv("jobs.csv",index=False,encoding ="utf-8")
print("Data saved to jobs.csv")
   
